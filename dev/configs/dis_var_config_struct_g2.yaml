# config on G2-server with structural context
exp_dir: ./scratch/
experiment: dis_esm480_seq_randneg500_i50
# experiment: debug
mode: train
device: cuda:0
batch_size: 16
pheno_batch_size: 32
scoring: wt-marginals  # one of wt-marginals, masked-marginals
# output_file: ./dms_ontoprot_wt_score.csv
init_lr: 0.001
# init_clr: 0.002
# clr_t0: 10
# lr_reduce_factor: 0.5
# lr_schedule_patience: 3
# clr_reduce_factor: 0.5
# clr_schedule_patience: 5
epochs: 20
use_adapter: False  # if true, will use adapter for fine tuning
adapter_targets: ['key', 'query']
#adapter_targets:  ["query", "key", "value", "intermediate.dense", "output.dense"]
# adapter_targets:  ["query", "key", "value", "output.dense"]

model:
  type: esm
  # protein_lm_path: /local/storage/yl986/script_hub/KeAP/pretrained  # KeAP model
  # protein_lm_path: zjunlp/OntoProtein
  protein_lm_path: facebook/esm2_t12_35M_UR50D  # ESM2 480
  # protein_lm_path: facebook/esm2_t30_150M_UR50D  # ESM2 640
  # protein_lm_path: facebook/esm2_t33_650M_UR50D  # ESM2 1280
  # protein_lm_path: facebook/esm1v_t33_650M_UR90S_1  # ESM-1v
  # protein_lm_path: facebook/esm1b_t33_650M_UR50S  # ESM-1b
  # protein_lm_path: zjunlp/OntoProtein
  text_lm_path: microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext  # PubMedBERT
  # decoder_config_path: /local/storage/yl986/script_hub/KeAP/initial_decoder_config/config.json
  frozen_bert: True
  # prot_bert_unfreeze: ['esm.encoder.layer.32']  # for esm-2 1280
  # prot_bert_unfreeze: ['esm.encoder.layer.29']  # for esm-2 640
  prot_bert_unfreeze: ['esm.encoder.layer.11']  # for esm-2 480
  # prot_bert_unfreeze: ['bert.encoder.layer.29']  # for OntoProtein
  # text_bert_unfreeze: ['bert.encoder.layer.11']
  # text_bert_unfreeze: ['bert.encoder.layer.11']
  text_bert_unfreeze: []
  w_l: 1  # weight applied to pathogenicity loss
  # margin: 0.25  # for cosine
  dist_fn_name: cosine_sigmoid
  margin: 0.25  # margin for contrast loss
  freq_norm_factor: 32  # normalization factor for in-context phenotype counts
  max_pathogenicity_epochs: 50  # number of epochs to train pathogencity objective
  num_warmup_epochs: 0
  topk: [10, 20, 50, 100]
  seq_weight_scaler: 1
  pheno_emb_update_interval: 50
  use_hardneg: False
  n_neg_samples: 500

dataset:
  task_name: var_pred
  # pdb_graph_dir: "/local/storage/yl986/data/NetFlow3D/graph/PDB_intra"
  # af_graph_dir: "/local/storage/yl986/data/NetFlow3D/graph/AF2_pLDDT0"
  pdb_graph_dir: "/home/yl986/data/NetFlow3D/graph/PDB_intra"
  af_graph_dir: "/home/yl986/data/NetFlow3D/graph/AF2_pLDDT0"
  seq_fasta: ["/home/yl986/data/UniProt/uniprot_sprot.fasta",
              "/home/yl986/data/UniProt/uniprot_sprot_varsplic.fasta"]
  prot_meta_data: ["/home/yl986/data/UniProt/meta/uniprot_sprot_human_meta.txt",
                   "/home/yl986/data/UniProt/meta/uniprot_trembl_human_meta.txt"]
  data_dir: /home/yl986/data/variant_data/pred/pheno_select/struct/
  input_file:
    train: train.csv
    test: test.csv
    val: val.csv
  phenotype_vocab_file: /home/yl986/data/variant_data/pred/pheno_select/phenotype_vocab.txt
  phenotype_desc_file: /home/yl986/data/variant_data/short_name2desc.json  # phenotype name-to-description
  use_pheno_desc: True
  context_agg_option: concat
  # pheno_emb_cache_file:
  pid_col: UniProt
  pos_col: Protein_position
  label_col: label
  pheno_col: pheno_clean
  load_variant: True
  use_protein_desc: True
  max_protein_seq_length: 1024
  half_window_size: 64
  # max_phenotype_length: null
  use_protein_desc: True
  use_struct_neighbor: False
  struct_radius_cutoff: 25
  use_struct_vocab: False  # enable structure-aware sequence
  struct_seq_file: '/home/yl986/data/variant_data/pred/prot_combine_seq.json'  # pre-processed structure-aware sequence (SaProt)
